# ğŸ‘ Fine-Tuned LLaMA SaaS API

Private LLM inference with fine-tuned LLaMA models.

## ğŸ§° Stack
- LLaMA
- FastAPI
- Stripe
- Redis

## ğŸ§  What Iâ€™m Learning
- Quantization + fine-tuning
- Stripe metered billing
- Redis caching & queues

## âœ… Roadmap
- [ ] Fine-tune small LLaMA model
- [ ] Deploy with FastAPI
- [ ] Add Redis rate limit/cache
- [ ] Stripe usage-based billing
- [ ] Admin dashboard (optional)

## ğŸ•“ Progress Log
- TBD
